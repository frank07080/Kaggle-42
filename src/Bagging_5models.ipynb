{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bagging_5models.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ee3d7d6e2eb74def992592eb622af6f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4a1aadd8d75842489e12581d3dfc930c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9acb6bad80944425b125ad1981b9f984","IPY_MODEL_5e7cc0dcf9954aeea57f841aaf82e5f6"]}},"4a1aadd8d75842489e12581d3dfc930c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9acb6bad80944425b125ad1981b9f984":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_efe46b38e5b64bf59d1acb6fbc4b31ff","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":4017,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4017,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16e0f4434235481eba0e58b2db2520dd"}},"5e7cc0dcf9954aeea57f841aaf82e5f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7a5f2e2a0ddc4ba8bfb6bd37b26770d0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 4017/4017 [00:02&lt;00:00, 1485.57it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f04b7c201bda42aaa0ca0b3eb73b2c15"}},"efe46b38e5b64bf59d1acb6fbc4b31ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"16e0f4434235481eba0e58b2db2520dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a5f2e2a0ddc4ba8bfb6bd37b26770d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f04b7c201bda42aaa0ca0b3eb73b2c15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"NjPpUBGTamrr","colab_type":"code","outputId":"3f30f961-34b1-4a58-9cf8-cf489d88cb51","executionInfo":{"status":"ok","timestamp":1583370453237,"user_tz":300,"elapsed":466,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["% tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Print TF version, keep the version in mind when you look the documentation.\n","print('TensorFlow version: {}'.format(tf.__version__))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["TensorFlow version: 2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4aKx3zBOhVVC","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import pandas as pd\n","import time, gc\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n","from matplotlib import pyplot as plt\n","import pyarrow.parquet as pq\n","from PIL import Image\n","from PIL import ImageEnhance\n","from keras.callbacks import ReduceLROnPlateau\n","from sklearn.metrics import accuracy_score\n","from scipy import stats\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_N2BvamNuDm","colab_type":"code","colab":{}},"source":["path = \"/content/drive/My Drive/Data/bengaliai-cv19/\" # TCC\n","# path=\"/content/drive/My Drive/data 2040 midterm private folder/Data/bengaliai-cv19/\" # LSY"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ylw56bl1hhHa","colab_type":"code","outputId":"44eb804d-da13-4c93-d7d4-a6aebd86bb19","executionInfo":{"status":"ok","timestamp":1583370455328,"user_tz":300,"elapsed":525,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ckUWiGk0Rsx9","colab_type":"text"},"source":["## Obtain Data from CSV and Parquet\n","\n","***The codes in model building and training are credit to [this pubic notebook](https://www.kaggle.com/kaushal2896/bengali-graphemes-starter-eda-multi-output-cnn)***\n","\n","Train, test label from CSV\n"]},{"cell_type":"code","metadata":{"id":"y_qQNx-TPgnF","colab_type":"code","colab":{}},"source":["train_df_ = pd.read_csv(path + 'train.csv')\n","test_df_ = pd.read_csv(path + 'test.csv')\n","class_map_df = pd.read_csv(path + 'class_map.csv')\n","sample_sub_df = pd.read_csv(path + 'sample_submission.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ojIVUTscrGGz","colab_type":"text"},"source":["## Enhancement Functions"]},{"cell_type":"markdown","metadata":{"id":"5m8dfj8mhgpw","colab_type":"text"},"source":["To increase training speed and model accuracy, the images are first cropped to fufill the image with characters and then resized to a 64 by 64 pixel image."]},{"cell_type":"code","metadata":{"id":"N-sMofTZHJR4","colab_type":"code","colab":{}},"source":["# resize the dataframe\n","from tqdm.auto import tqdm\n","def resize(df, size=96, need_progress_bar=True, sharpness=3.0):\n","    resized = {}\n","    resize_size=96\n","    if need_progress_bar:\n","        for i in tqdm(range(df.shape[0])):\n","            image=df.loc[df.index[i]].values.reshape(137,236)\n","            # Add sharpness\n","            # image = Image.fromarray(image)\n","            # image = ImageEnhance.Sharpness(image)\n","            # image = image.enhance(sharpness)\n","            # image = np.array(image)\n","            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","\n","            idx = 0 \n","            ls_xmin = []\n","            ls_ymin = []\n","            ls_xmax = []\n","            ls_ymax = []\n","            for cnt in contours:\n","                idx += 1\n","                x,y,w,h = cv2.boundingRect(cnt)\n","                ls_xmin.append(x)\n","                ls_ymin.append(y)\n","                ls_xmax.append(x + w)\n","                ls_ymax.append(y + h)\n","            xmin = min(ls_xmin)\n","            ymin = min(ls_ymin)\n","            xmax = max(ls_xmax)\n","            ymax = max(ls_ymax)\n","\n","            roi = image[ymin:ymax,xmin:xmax]\n","            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n","            resized[df.index[i]] = resized_roi.reshape(-1)\n","    else:\n","        for i in range(df.shape[0]):\n","            image=df.loc[df.index[i]].values.reshape(137,236)\n","            # Add sharpness\n","            # image = Image.fromarray(image)\n","            # image = ImageEnhance.Sharpness(image)\n","            # image = image.enhance(sharpness)\n","            # image = np.array(image)\n","            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","            idx = 0 \n","            ls_xmin = []\n","            ls_ymin = []\n","            ls_xmax = []\n","            ls_ymax = []\n","            for cnt in contours:\n","                idx += 1\n","                x,y,w,h = cv2.boundingRect(cnt)\n","                ls_xmin.append(x)\n","                ls_ymin.append(y)\n","                ls_xmax.append(x + w)\n","                ls_ymax.append(y + h)\n","            xmin = min(ls_xmin)\n","            ymin = min(ls_ymin)\n","            xmax = max(ls_xmax)\n","            ymax = max(ls_ymax)\n","\n","            roi = image[ymin:ymax,xmin:xmax]\n","            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n","            resized[df.index[i]] = resized_roi.reshape(-1)\n","    resized = pd.DataFrame(resized).T\n","    return resized"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WcWrPR7qv5BR","colab_type":"code","colab":{}},"source":["# Build DataGenerator\n","class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n","\n","    def flow(self,\n","             x,\n","             y=None,\n","             batch_size=32,\n","             shuffle=True,\n","             sample_weight=None,\n","             seed=None,\n","             save_to_dir=None,\n","             save_prefix='',\n","             save_format='png',\n","             subset=None):\n","\n","        targets = None\n","        target_lengths = {}\n","        ordered_outputs = []\n","        for output, target in y.items():\n","            if targets is None:\n","                targets = target\n","            else:\n","                targets = np.concatenate((targets, target), axis=1)\n","            target_lengths[output] = target.shape[1]\n","            ordered_outputs.append(output)\n","\n","\n","        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n","                                         shuffle=shuffle):\n","            target_dict = {}\n","            i = 0\n","            for output in ordered_outputs:\n","                target_length = target_lengths[output]\n","                target_dict[output] = flowy[:, i: i + target_length]\n","                i += target_length\n","\n","            yield flowx, target_dict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIRERI6_5LPq","colab_type":"code","colab":{}},"source":["IMG_SIZE=96\n","N_CHANNELS=1\n","batch_size = 256\n","epochs = 30\n","HEIGHT = 137\n","WIDTH = 236"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IOrqtazSizQv","colab_type":"text"},"source":["## Model Bagging"]},{"cell_type":"code","metadata":{"id":"u-b_XYyKPKmR","colab_type":"code","colab":{}},"source":["vanilla_96 = tf.keras.models.load_model('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/vanilla_96_model.h5')\n","vanilla_96.load_weights('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/vanilla_96_model.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOp5FDE4uSVa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4012b5ee-7668-449b-b537-4f4c03ca3082","executionInfo":{"status":"ok","timestamp":1583352606958,"user_tz":300,"elapsed":24127,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}}},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(vanilla_96)\n","converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n","vanilla_96 = converter.convert()\n","open('vanilla_96.tflite', 'wb').write(vanilla_96)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15009584"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"JqCkThT-PZf4","colab_type":"code","colab":{}},"source":["moredense_96 = tf.keras.models.load_model('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/96_more_dense_model.h5')\n","moredense_96.load_weights('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/96_more_dense_model.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9swSWRyRluai","colab_type":"code","outputId":"e6cbea00-c2ad-477c-8e06-15427a201457","executionInfo":{"status":"ok","timestamp":1583352620043,"user_tz":300,"elapsed":36235,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(moredense_96)\n","converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n","moredense_96 = converter.convert()\n","open('moredense_96.tflite', 'wb').write(moredense_96)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15495136"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"dc2sVlAAQqcC","colab_type":"code","colab":{}},"source":["moredense_96_moretrain = tf.keras.models.load_model('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/96_more_dense_model_moretrain.h5')\n","moredense_96_moretrain.load_weights('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/96_more_dense_model_moretrain.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UvhbpOzfl5Fl","colab_type":"code","outputId":"90c31bc2-6afa-4b16-9e20-fb79a014c7cc","executionInfo":{"status":"ok","timestamp":1583352632038,"user_tz":300,"elapsed":46281,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(moredense_96_moretrain)\n","converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n","moredense_96_moretrain = converter.convert()\n","open('moredense_96_moretrain.tflite', 'wb').write(moredense_96_moretrain)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15495136"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"PRWlcMx1QzuT","colab_type":"code","colab":{}},"source":["densenet2 = tf.keras.models.load_model('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/saved_models/LSY_MODEL_densenet2.h5')\n","densenet2.load_weights('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/saved_models/LSY_MODEL_densenet2.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFF1aVHJl9mm","colab_type":"code","outputId":"3973d6df-16bc-48b6-c39b-cd03416441a1","executionInfo":{"status":"ok","timestamp":1583352668773,"user_tz":300,"elapsed":81840,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(densenet2)\n","converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n","densenet2 = converter.convert()\n","open('densenet2.tflite', 'wb').write(densenet2)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9809736"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"RLl7-2v_Ryh2","colab_type":"code","colab":{}},"source":["densenet4_2 = tf.keras.models.load_model('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/saved_models/LSY_MODEL_densenet4.2.h5')\n","densenet4_2.load_weights('/content/drive/My Drive/Data/bengaliai-cv19/saved_modelssss/saved_models/LSY_MODEL_densenet4.2.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PShaKTVamHlt","colab_type":"code","outputId":"b2b71505-6f06-4fb0-cf92-cd149a14335f","executionInfo":{"status":"ok","timestamp":1583352706111,"user_tz":300,"elapsed":118071,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(densenet4_2)\n","converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n","densenet4_2 = converter.convert()\n","open('densenet4_2.tflite', 'wb').write(densenet4_2)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9829088"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"HDzfYxOpaALi","colab_type":"code","colab":{}},"source":["vanilla_96 = tf.lite.Interpreter(model_path=\"vanilla_96.tflite\")\n","vanilla_96.allocate_tensors()\n","moredense_96 = tf.lite.Interpreter(model_path=\"moredense_96.tflite\")\n","moredense_96.allocate_tensors()\n","moredense_96_moretrain = tf.lite.Interpreter(model_path=\"moredense_96_moretrain.tflite\")\n","moredense_96_moretrain.allocate_tensors()\n","densenet2 = tf.lite.Interpreter(model_path=\"densenet2.tflite\")\n","densenet2.allocate_tensors()\n","densenet4_2 = tf.lite.Interpreter(model_path=\"densenet4_2.tflite\")\n","densenet4_2.allocate_tensors()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U100LGYjUG_F","colab_type":"code","colab":{}},"source":["models = (vanilla_96, moredense_96, moredense_96_moretrain, densenet2, densenet4_2)\n","input_details = vanilla_96.get_input_details()\n","output_details = vanilla_96.get_output_details()\n","input_shape = input_details[0]['shape']\n","input_index = input_details[0]['index']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CIiJTOGzBrt5","colab_type":"code","colab":{}},"source":["i = 0\n","df_test_img = pd.read_parquet(path + f'test_image_data_{i}.parquet') \n","df_test_img.set_index('image_id', inplace=True)\n","\n","X_test = resize(df_test_img, need_progress_bar=False)/255\n","X_test = tf.convert_to_tensor(X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQOJBznnmu7a","colab_type":"code","colab":{}},"source":["def bagging_pred_lite(x, models):\n","    \"\"\"Bagging the input models, for lite models\"\"\"\n","    len_model = len(models)\n","    dict_pred_func = {}\n","\n","    def predict_results(input_data):\n","        \"\"\"Return mode of model preidctions\"\"\"\n","        # input_data_2 = np.array(input_data)\n","        # input_data_2 = input_data\n","        temp_pred = np.empty([3, len_model])\n","        for model_idx, model in enumerate(models):\n","            model.set_tensor(input_index, input_data)\n","            model.invoke()\n","            temp_pred[0][model_idx] = np.argmax(model.get_tensor(output_details[0]['index']))\n","            temp_pred[1][model_idx] = np.argmax(model.get_tensor(output_details[1]['index']))\n","            temp_pred[2][model_idx] = np.argmax(model.get_tensor(output_details[2]['index']))\n","        return stats.mode(temp_pred, axis=1)[0]\n","\n","    @tf.function\n","    def map_predictions(data):\n","        return tf.map_fn(predict_results, data, parallel_iterations=1024, dtype=tf.float32)\n","    \n","\n","    bagging_preds = np.transpose(map_predictions(x))[0]\n","\n","    for key_idx, key in enumerate(('grapheme_root', 'vowel_diacritic', 'consonant_diacritic')):\n","        dict_pred_func[key] = bagging_preds[key_idx]\n","\n","    return dict_pred_func"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uhKmAyYo2Vm","colab_type":"code","colab":{}},"source":["bagging_pred_lite(X_test, models)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmQvbfDWYuUe","colab_type":"code","colab":{}},"source":["def bagging_pred(x, models):\n","    \"\"\"Bagging the input models, for full models\"\"\"\n","    len_model = len(models)\n","    dict_pred = {\n","    'grapheme_root': np.empty([x.shape[0], len_model]),\n","    'vowel_diacritic': np.empty([x.shape[0], len_model]),\n","    'consonant_diacritic': np.empty([x.shape[0], len_model]),\n","    }\n","    for model_idx, model in enumerate(models):\n","        preds = model.predict(x)\n","        for i, p in enumerate(dict_pred):\n","            dict_pred[p][:, model_idx] = np.argmax(preds[i], axis=1)\n","    \n","    for key in dict_pred.keys():\n","        dict_pred[key] = np.transpose(stats.mode(dict_pred[key], axis=1)[0])[0]\n","\n","    return dict_pred"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bhsyPEc5y9Xe","colab_type":"code","outputId":"108045bc-78f8-4490-88b6-6e9abab65133","executionInfo":{"status":"error","timestamp":1583370775564,"user_tz":300,"elapsed":29820,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":284,"referenced_widgets":["ee3d7d6e2eb74def992592eb622af6f1","4a1aadd8d75842489e12581d3dfc930c","9acb6bad80944425b125ad1981b9f984","5e7cc0dcf9954aeea57f841aaf82e5f6","efe46b38e5b64bf59d1acb6fbc4b31ff","16e0f4434235481eba0e58b2db2520dd","7a5f2e2a0ddc4ba8bfb6bd37b26770d0","f04b7c201bda42aaa0ca0b3eb73b2c15"]}},"source":["# Separate preidtions\n","dict_pred = {\n","    'grapheme_root': np.zeros(6),\n","    'vowel_diacritic': np.zeros(6),\n","    'consonant_diacritic': np.zeros(6),\n","    'total': np.zeros(6)\n","}\n","for model_count, model in enumerate(models):\n","    components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n","    count = 0\n","    for i in range(4):\n","        train_df = pd.merge(pd.read_parquet(path+f'train_image_data_{i}.parquet'), train_df_, on='image_id').drop(['image_id', 'grapheme'], axis=1)\n","        X_train = train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1)\n","        \n","        Y_train_root = pd.get_dummies(train_df['grapheme_root']).values\n","        Y_train_vowel = pd.get_dummies(train_df['vowel_diacritic']).values\n","        Y_train_consonant = pd.get_dummies(train_df['consonant_diacritic']).values\n","\n","        # Divide the data into training and validation set\n","        x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = train_test_split(X_train, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.08, random_state=666)\n","        del train_df\n","        del X_train\n","        del Y_train_root, Y_train_vowel, Y_train_consonant\n","        del x_train\n","        del y_train_root\n","        del y_train_vowel\n","        del y_train_consonant\n","\n","        x_test = resize(x_test)/255\n","        x_test = x_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n","\n","        preds = model.predict(x_test)\n","        y_true = np.array([\n","            np.argmax(y_test_root, axis=1), \n","            np.argmax(y_test_vowel, axis=1), \n","            np.argmax(y_test_consonant, axis=1)\n","            ])\n","        for pred_idx in range(len(preds)):\n","            preds[pred_idx] = np.argmax(preds[pred_idx], axis=1)\n","\n","        acc = preds == y_true\n","        dict_pred['grapheme_root'][model_count] += np.sum(acc[0])\n","        dict_pred['vowel_diacritic'][model_count] += np.sum(acc[1])\n","        dict_pred['consonant_diacritic'][model_count] += np.sum(acc[2])\n","        ds_len = x_test.shape[0]\n","        dict_pred['total'][model_count] += np.sum(np.sum(acc, axis=0) == np.full((1, ds_len), 3))\n","        count += ds_len\n","        \n","        # Delete to reduce memory usage\n","        del x_test\n","        del y_test_root\n","        del y_test_vowel\n","        del y_test_consonant\n","        del y_true\n","\n","    for key in dict_pred.keys():\n","        dict_pred[key][model_count] /= count"],"execution_count":54,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee3d7d6e2eb74def992592eb622af6f1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=4017), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-960b145577d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_CHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         y_true = np.array([\n\u001b[1;32m     33\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Interpreter' object has no attribute 'predict'"]}]},{"cell_type":"code","metadata":{"id":"2rV_9S5zq2s_","colab_type":"code","colab":{}},"source":["# bagging predictions\n","count = 0\n","for i in range(4):\n","    train_df = pd.merge(pd.read_parquet(path+f'train_image_data_{i}.parquet'), train_df_, on='image_id').drop(['image_id', 'grapheme'], axis=1)\n","    X_train = train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1)\n","    \n","    Y_train_root = pd.get_dummies(train_df['grapheme_root']).values\n","    Y_train_vowel = pd.get_dummies(train_df['vowel_diacritic']).values\n","    Y_train_consonant = pd.get_dummies(train_df['consonant_diacritic']).values\n","\n","    # Divide the data into training and validation set\n","    x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = train_test_split(X_train, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.08, random_state=666)\n","    del train_df\n","    del X_train\n","    del Y_train_root, Y_train_vowel, Y_train_consonant\n","    del x_train\n","    del y_train_root\n","    del y_train_vowel\n","    del y_train_consonant\n","\n","    x_test = resize(x_test)/255\n","    x_test = x_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n","\n","    preds = bagging_pred_lite(x_test, models)\n","    y_true = np.array([\n","        np.argmax(y_test_root, axis=1), \n","        np.argmax(y_test_vowel, axis=1), \n","        np.argmax(y_test_consonant, axis=1)\n","        ])\n","    \n","    preds_array = []\n","    for pred_key in ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']:\n","        preds_array.append(preds[pred_key])\n","\n","    acc = np.array(preds_array) == y_true\n","    dict_pred['grapheme_root'][5] += np.sum(acc[0])\n","    dict_pred['vowel_diacritic'][5] += np.sum(acc[1])\n","    dict_pred['consonant_diacritic'][5] += np.sum(acc[2])\n","    ds_len = x_test.shape[0]\n","    dict_pred['total'][5] += np.sum(np.sum(acc, axis=0) == np.full((1, ds_len), 3))\n","    count += ds_len\n","    \n","    # Delete to reduce memory usage\n","    del x_test\n","    del y_test_root\n","    del y_test_vowel\n","    del y_test_consonant\n","    del y_true\n","\n","for key in dict_pred.keys():\n","    dict_pred[key][5] /= count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rk7zOwgNsSsX","colab_type":"code","outputId":"0f279de3-c00a-42f0-f969-f3f1c7ed5742","executionInfo":{"status":"ok","timestamp":1583370775994,"user_tz":300,"elapsed":420,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["df_pred_eval = pd.DataFrame(dict_pred, index=['vanilla_96', 'moredense_96', 'moredense_96_moretrain', 'densenet2', 'densenet4_2', 'bagging'])\n","df_pred_eval"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>grapheme_root</th>\n","      <th>vowel_diacritic</th>\n","      <th>consonant_diacritic</th>\n","      <th>total</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>vanilla_96</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>moredense_96</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>moredense_96_moretrain</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>densenet2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>densenet4_2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>bagging</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        grapheme_root  ...  total\n","vanilla_96                        0.0  ...    0.0\n","moredense_96                      0.0  ...    0.0\n","moredense_96_moretrain            0.0  ...    0.0\n","densenet2                         0.0  ...    0.0\n","densenet4_2                       0.0  ...    0.0\n","bagging                           0.0  ...    0.0\n","\n","[6 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"9DWeKo7RFfoW","colab_type":"code","outputId":"eddf99fe-b081-4e36-d4af-0463b67ceb99","executionInfo":{"status":"ok","timestamp":1583214418000,"user_tz":300,"elapsed":18359,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":194}},"source":["# Test Data\n","components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n","target=[] # model predictions placeholder\n","row_id=[] # row_id place holder\n","for i in range(4):\n","    df_test_img = pd.read_parquet(path + f'test_image_data_{i}.parquet') \n","    df_test_img.set_index('image_id', inplace=True)\n","\n","    X_test = resize(df_test_img, need_progress_bar=False)/255\n","    X_test = X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n","    \n","    dict_pred = bagging_pred(X_test, models)\n","\n","    for k,id in enumerate(df_test_img.index.values):  \n","        for i,comp in enumerate(components):\n","            id_sample=id+'_'+comp\n","            row_id.append(id_sample)\n","            target.append(dict_pred[comp][k])\n","    del df_test_img\n","    del X_test\n","    gc.collect()\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","df_sample.to_csv('submission.csv',index=False)\n","df_sample.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test_0_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Test_0_grapheme_root</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test_0_vowel_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Test_1_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Test_1_grapheme_root</td>\n","      <td>93</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       row_id  target\n","0  Test_0_consonant_diacritic       0\n","1        Test_0_grapheme_root       3\n","2      Test_0_vowel_diacritic       0\n","3  Test_1_consonant_diacritic       0\n","4        Test_1_grapheme_root      93"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"086ZLoH1cma3","colab_type":"code","outputId":"dfc6ba83-5a14-4d38-f143-faec2daf7d19","executionInfo":{"status":"ok","timestamp":1583214387406,"user_tz":300,"elapsed":1253,"user":{"displayName":"Cangcheng Tang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSkdWZmO11XETH_LN46ESKbrYROCdPqE1ecgjmxw=s64","userId":"08058496277274525082"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df_sample"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test_0_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Test_0_grapheme_root</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test_0_vowel_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Test_1_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Test_1_grapheme_root</td>\n","      <td>93.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Test_1_vowel_diacritic</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Test_2_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Test_2_grapheme_root</td>\n","      <td>19.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Test_2_vowel_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Test_3_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Test_3_grapheme_root</td>\n","      <td>115.0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Test_3_vowel_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Test_4_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Test_4_grapheme_root</td>\n","      <td>55.0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Test_4_vowel_diacritic</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Test_5_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Test_5_grapheme_root</td>\n","      <td>115.0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Test_5_vowel_diacritic</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Test_6_consonant_diacritic</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Test_6_grapheme_root</td>\n","      <td>147.0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Test_6_vowel_diacritic</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Test_7_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Test_7_grapheme_root</td>\n","      <td>137.0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Test_7_vowel_diacritic</td>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Test_8_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Test_8_grapheme_root</td>\n","      <td>119.0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Test_8_vowel_diacritic</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Test_9_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Test_9_grapheme_root</td>\n","      <td>133.0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Test_9_vowel_diacritic</td>\n","      <td>10.0</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Test_10_consonant_diacritic</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Test_10_grapheme_root</td>\n","      <td>148.0</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Test_10_vowel_diacritic</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Test_11_consonant_diacritic</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Test_11_grapheme_root</td>\n","      <td>21.0</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Test_11_vowel_diacritic</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         row_id  target\n","0    Test_0_consonant_diacritic     0.0\n","1          Test_0_grapheme_root     3.0\n","2        Test_0_vowel_diacritic     0.0\n","3    Test_1_consonant_diacritic     0.0\n","4          Test_1_grapheme_root    93.0\n","5        Test_1_vowel_diacritic     2.0\n","6    Test_2_consonant_diacritic     0.0\n","7          Test_2_grapheme_root    19.0\n","8        Test_2_vowel_diacritic     0.0\n","9    Test_3_consonant_diacritic     0.0\n","10         Test_3_grapheme_root   115.0\n","11       Test_3_vowel_diacritic     0.0\n","12   Test_4_consonant_diacritic     0.0\n","13         Test_4_grapheme_root    55.0\n","14       Test_4_vowel_diacritic     4.0\n","15   Test_5_consonant_diacritic     0.0\n","16         Test_5_grapheme_root   115.0\n","17       Test_5_vowel_diacritic     2.0\n","18   Test_6_consonant_diacritic     5.0\n","19         Test_6_grapheme_root   147.0\n","20       Test_6_vowel_diacritic     9.0\n","21   Test_7_consonant_diacritic     0.0\n","22         Test_7_grapheme_root   137.0\n","23       Test_7_vowel_diacritic     7.0\n","24   Test_8_consonant_diacritic     0.0\n","25         Test_8_grapheme_root   119.0\n","26       Test_8_vowel_diacritic     9.0\n","27   Test_9_consonant_diacritic     0.0\n","28         Test_9_grapheme_root   133.0\n","29       Test_9_vowel_diacritic    10.0\n","30  Test_10_consonant_diacritic     4.0\n","31        Test_10_grapheme_root   148.0\n","32      Test_10_vowel_diacritic     1.0\n","33  Test_11_consonant_diacritic     0.0\n","34        Test_11_grapheme_root    21.0\n","35      Test_11_vowel_diacritic     2.0"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"K8J2FZjuGqiB","colab_type":"text"},"source":["## For submission"]},{"cell_type":"code","metadata":{"id":"LBrePUg0Gojm","colab_type":"code","colab":{}},"source":["# # This Python 3 environment comes with many helpful analytics libraries installed\n","# # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# # For example, here's several helpful packages to load in \n","\n","# import numpy as np # linear algebra\n","# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# # Input data files are available in the \"../input/\" directory.\n","# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# # Any results you write to the current directory are saved as output.\n","\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import os\n","import pandas as pd\n","import time, gc\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n","from matplotlib import pyplot as plt\n","import pyarrow.parquet as pq\n","from PIL import Image\n","from PIL import ImageEnhance\n","from keras.callbacks import ReduceLROnPlateau\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n","from sklearn.metrics import accuracy_score\n","from scipy import stats\n","import pickle\n","\n","\n","# load models\n","path = '/kaggle/input/bagging'\n","\n","vanilla_96 = tf.keras.models.load_model(path + '/vanilla_96_model.h5')\n","vanilla_96.load_weights(path + '/vanilla_96_model.h5')\n","\n","moredense_96 = tf.keras.models.load_model(path + '/96_more_dense_model.h5')\n","moredense_96.load_weights(path + '/96_more_dense_model.h5')\n","\n","moredense_96_moretrain = tf.keras.models.load_model(path + '/96_more_dense_model_moretrain.h5')\n","moredense_96_moretrain.load_weights(path + '/96_more_dense_model_moretrain.h5')\n","\n","models = (vanilla_96, moredense_96, moredense_96_moretrain)\n","\n","\n","IMG_SIZE=96\n","N_CHANNELS=1\n","batch_size = 256\n","epochs = 30\n","HEIGHT = 137\n","WIDTH = 236\n","\n","\n","# bagging function\n","def bagging_pred(x, models):\n","    len_model = len(models)\n","    dict_pred = {\n","    'grapheme_root': np.empty([x.shape[0], len_model]),\n","    'vowel_diacritic': np.empty([x.shape[0], len_model]),\n","    'consonant_diacritic': np.empty([x.shape[0], len_model]),\n","    }\n","    for model_idx, model in enumerate(models):\n","        preds = model.predict(x)\n","        for i, p in enumerate(dict_pred):\n","            dict_pred[p][:, model_idx] = np.argmax(preds[i], axis=1)\n","    \n","    for key in dict_pred.keys():\n","        dict_pred[key] = np.transpose(stats.mode(dict_pred[key], axis=1)[0])[0]\n","\n","    return dict_pred\n","\n","# Clean Data\n","# resize the dataframe\n","from tqdm.auto import tqdm\n","def resize(df, size=96, need_progress_bar=True, sharpness=3.0):\n","    resized = {}\n","    resize_size=96\n","    if need_progress_bar:\n","        for i in tqdm(range(df.shape[0])):\n","            image=df.loc[df.index[i]].values.reshape(137,236)\n","            # Add sharpness\n","            image = Image.fromarray(image)\n","            image = ImageEnhance.Sharpness(image)\n","            image = image.enhance(sharpness)\n","            image = np.array(image)\n","            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","\n","            idx = 0 \n","            ls_xmin = []\n","            ls_ymin = []\n","            ls_xmax = []\n","            ls_ymax = []\n","            for cnt in contours:\n","                idx += 1\n","                x,y,w,h = cv2.boundingRect(cnt)\n","                ls_xmin.append(x)\n","                ls_ymin.append(y)\n","                ls_xmax.append(x + w)\n","                ls_ymax.append(y + h)\n","            xmin = min(ls_xmin)\n","            ymin = min(ls_ymin)\n","            xmax = max(ls_xmax)\n","            ymax = max(ls_ymax)\n","\n","            roi = image[ymin:ymax,xmin:xmax]\n","            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n","            resized[df.index[i]] = resized_roi.reshape(-1)\n","    else:\n","        for i in range(df.shape[0]):\n","            image=df.loc[df.index[i]].values.reshape(137,236)\n","            # Add sharpness\n","            image = Image.fromarray(image)\n","            image = ImageEnhance.Sharpness(image)\n","            image = image.enhance(sharpness)\n","            image = np.array(image)\n","            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","            idx = 0 \n","            ls_xmin = []\n","            ls_ymin = []\n","            ls_xmax = []\n","            ls_ymax = []\n","            for cnt in contours:\n","                idx += 1\n","                x,y,w,h = cv2.boundingRect(cnt)\n","                ls_xmin.append(x)\n","                ls_ymin.append(y)\n","                ls_xmax.append(x + w)\n","                ls_ymax.append(y + h)\n","            xmin = min(ls_xmin)\n","            ymin = min(ls_ymin)\n","            xmax = max(ls_xmax)\n","            ymax = max(ls_ymax)\n","\n","            roi = image[ymin:ymax,xmin:xmax]\n","            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n","            resized[df.index[i]] = resized_roi.reshape(-1)\n","    resized = pd.DataFrame(resized).T\n","    return resized\n","\n","\n","\n","# Test Data\n","# Test Data\n","components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n","target=[] # model predictions placeholder\n","row_id=[] # row_id place holder\n","for i in range(4):\n","    df_test_img = pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_{}.parquet'.format(i)) \n","    df_test_img.set_index('image_id', inplace=True)\n","\n","    X_test = resize(df_test_img, need_progress_bar=False)/255\n","    X_test = X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n","    \n","    dict_pred = bagging_pred(X_test, models)\n","\n","    for k,id in enumerate(df_test_img.index.values):  \n","        for i,comp in enumerate(components):\n","            id_sample=id+'_'+comp\n","            row_id.append(id_sample)\n","            target.append(dict_pred[comp][k])\n","    del df_test_img\n","    del X_test\n","    gc.collect()\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","df_sample.to_csv('submission.csv',index=False)\n","df_sample"],"execution_count":0,"outputs":[]}]}